{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capsule Networks\n",
    "\n",
    "Implemented using tensorflow<br>\n",
    "Based on the papter \"Dynamic Routing Between Capsules\"<br>\n",
    "\n",
    "## Requirement\n",
    "\n",
    "+ python3\n",
    "+ Tensorflow\n",
    "+ NumPy\n",
    "+ Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST Datasets\n",
    "+ image (handwritten digit): 28 * 28 = 784 pixels\n",
    "+ corresponding label (one of 0, 1, 2, ..., 9) in 'one_hot vector' format\n",
    "+ train / validation / test instances: 55000 / 5000 / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./MNIST_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Reset model), Define session\n",
    "+ tf.reset_default_graph() to reset the model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Images\n",
    "+ $X$ is a placeholder for the input image(28×28 pixels, 1 color channel = grayscale)\n",
    "+ $y$ for the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape=[None, 28, 28, 1], dtype = tf.float32)\n",
    "\n",
    "y = tf.placeholder(shape=[None], dtype=tf.int64)\n",
    "T = tf.one_hot(y, depth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layer\n",
    "+ $convLayer$ is the first layer with 256, 9 × 9 convolution kernels with a stride of 1 and ReLU activation\n",
    "+  This layer converts pixel intensities to the activities of local feature detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convLayer = tf.layers.conv2d(X, filters=256, kernel_size=9, strides=1, padding=\"valid\", activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary Capsules\n",
    "+ The second layer ($PrimaryCaps$) is a convolutional capsule layer with 32 channels of convolutional 8D capsules\n",
    "+ Each primary capsule contains 8 convolutional units with a 9 × 9 kernel and a stride of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "primaryCaps = tf.layers.conv2d(convLayer, filters=32*8, kernel_size=9, strides=2, padding=\"valid\", activation=tf.nn.relu)\n",
    "primaryCaps_reshaped = tf.reshape(primaryCaps, [-1, 1152, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ $u_i$ is an output of the Primary Capsule Using the __Squash Function__, $squash$.\n",
    "+ The length of the output vector of a capsule to represent the probability that the entity represented by the capsule is present in the current input.<br>$\\rightarrow$ The length of the output vector has to be a value between 0 and 1.\n",
    "+ __Squashing__: to ensure that short vectors get shrunk to almost zero length and long vectors get shrunk to length slightly below 1.\n",
    "$$v_j = \\frac{\\|s_j\\|^2}{1+\\|s_j\\|^2}\\frac{s_j}{\\|s_j\\|}$$\n",
    "+ $v_j$ is the vector output of capsule $j$ and $s_j$ is its total input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(s, axis):\n",
    "    epsilon = 1e-9\n",
    "    s_squaredNorm = tf.reduce_sum(tf.square(s),axis=axis, keep_dims=True)\n",
    "    unitVector = s / (tf.sqrt(s_squaredNorm+epsilon))\n",
    "    squashFactor = s_squaredNorm / (1. + s_squaredNorm)\n",
    "    return squashFactor * unitVector\n",
    "\n",
    "u_i = squash(primaryCaps_reshaped,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digit Capsules\n",
    "Digit capsules calculate the \"prediction vectors\" $\\hat{u}_{j|i}$ for every $i,j$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u_i_expanded = tf.expand_dims(u_i, -1)\n",
    "u_i_tile = tf.expand_dims(u_i_expanded,2)\n",
    "u_i_tiled = tf.tile(u_i_tile, [1, 1, 10, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ $W$ is an transformation matrix and $u\\_i$ is an output of a capsule.\n",
    "+ _tf.tile()_ is used to tile the transformation matrices <br>$\\rightarrow$ useful for the parallel computation of matrix multiplication in GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = tf.shape(X)[0]\n",
    "\n",
    "W_init = tf.random_normal(shape=(1,1152,10, 16,8),stddev=0.01, dtype=tf.float32)\n",
    "W = tf.Variable(W_init)\n",
    "W_tiled = tf.tile(W,[batch_size,1,1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Multiply $W\\_tiled$ and $u\\_i\\_tiled$ to calculate $u\\_hat$\n",
    "$$ \\hat{u}_{j|i} = W_{ij}u_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_hat = tf.matmul(W_tiled, u_i_tiled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routing algorithm\n",
    "+ The for clause below is the __Procedure 1__, \"Routing algorithm\" in the paper.\n",
    "+ The number of routing interation is set to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "routingNum = 3\n",
    "\n",
    "b_ij = tf.zeros([batch_size,1152,10,1,1],dtype=np.float32)\n",
    "\n",
    "for i in range(routingNum):\n",
    "    c_i = tf.nn.softmax(b_ij, dim=2)\n",
    "    s_j = tf.reduce_sum(tf.multiply(c_i, u_hat), axis=1, keep_dims=True)\n",
    "    v_j = squash(s_j, axis=-2)\n",
    "    v_j_tiled = tf.tile(v_j, [1,1152,1,1,1])\n",
    "    a_ij = tf.matmul(u_hat, v_j_tiled, transpose_a=True)\n",
    "    b_ij = tf.add(b_ij, a_ij)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Margin Loss for digit existence\n",
    "+ A separate margin loss $L_k$ can be formulated as follows, $$L_k=T_k max(0,m^+-\\|v_k\\|)^2+\\lambda(1-T_k)max(0,\\|v_k\\|-m^-)^2$$  where $T_k=1$ if a digit of class $k$ is present and $m^+=0.9$ and $m^-=0.1$.\n",
    "+ $present\\_error$ represents $max(0,m^+-\\|v_k\\|)^2$ and $absent\\_error$ represents $max(0,\\|v_k\\|-m^-)^2$ in the equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5\n",
    "epsilon = 1e-9\n",
    "\n",
    "v_j_norm = tf.sqrt(tf.reduce_sum(tf.square(v_j), axis=-2, keep_dims=True)+epsilon)\n",
    "\n",
    "present_error = tf.reshape(tf.square(tf.maximum(0.,m_plus - v_j_norm)),shape=(-1,10))\n",
    "absent_error = tf.reshape(tf.square(tf.maximum(0.,v_j_norm - m_minus)),shape=(-1,10))\n",
    "\n",
    "L = tf.add(T*present_error, lambda_*(1.0 - T)*absent_error)\n",
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction\n",
    "+ Reconstruction loss is used to encourage the digit capsules to encode the instantiation parameters of the input digit.\n",
    "+ The length of the output vectors($y\\_proba$) represent the class probabilities\n",
    "+ $y\\_pred$ is the predicted lable based on the longest output vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = tf.sqrt(tf.reduce_sum(tf.square(v_j), axis=-2, keep_dims=False)+epsilon)\n",
    "y_ = tf.argmax(y_proba, axis=2)\n",
    "\n",
    "y_pred = tf.squeeze(y_, axis=[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "+ The decoder consists of 3 fully connected layers that model the pixel intensities as described in the figure below.\n",
    "+ The output of the digit capsule($v\\_j$) is fed into a decoder.\n",
    "+ We use the true label($y$) as reconstruction target($reconstruction\\_targets$) during training.\n",
    "<img src=\"./images/Fig1_decoder.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_labels = tf.placeholder_with_default(False, shape=())\n",
    "\n",
    "reconstruction_targets = tf.cond(masked_labels, lambda: y, lambda: y_pred)\n",
    "reconstruction_mask = tf.one_hot(reconstruction_targets, depth=10)\n",
    "reconstruction_mask_reshaped = tf.reshape(reconstruction_mask,[-1,1,10,1,1])\n",
    "v_masked = tf.multiply(v_j, reconstruction_mask_reshaped)\n",
    "\n",
    "decoder_input=tf.reshape(v_masked,[-1,10*16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Layers of the Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1Num = 512\n",
    "hidden2Num = 1024\n",
    "outputNum = 28 * 28\n",
    "\n",
    "hidden1 = tf.layers.dense(decoder_input, hidden1Num, activation=tf.nn.relu)\n",
    "hidden2 = tf.layers.dense(hidden1, hidden2Num, activation=tf.nn.relu)\n",
    "decoder_output = tf.layers.dense(hidden2, outputNum, activation=tf.nn.sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction Loss\n",
    "+ The reconstruction loss is the sum of squared differences between the outputs of the logistic units and the pixel intensities($decoder\\_output$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_flat = tf.reshape(X, [-1,outputNum])\n",
    "reconstruction_loss = tf.reduce_sum(tf.square(X_flat - decoder_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Loss\n",
    "+ The reconstruction loss is scaled down by 0.005 so that it does not dominate the margin loss during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0005\n",
    "loss = tf.add(margin_loss, alpha*reconstruction_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.equal(y, y_pred)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "+ TensorFlow default Adam optimizer is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## Training and Evaluation\n",
    "+ The batch size at each train step is 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model, Iteration: 429/429 Loss: 1.37338\n",
      "Epoch: 1  Training accuracy: 91.5592%  Average Loss: 2.466595\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 1.29436\n",
      "Epoch: 1  Validation accuracy: 97.6362%  Average Loss: 1.335619\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.87744\n",
      "Epoch: 2  Training accuracy: 98.0223%  Average Loss: 1.120595\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.88947\n",
      "Epoch: 2  Validation accuracy: 98.2171%  Average Loss: 0.928466\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.76576\n",
      "Epoch: 3  Training accuracy: 98.6069%  Average Loss: 0.838518\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.74825\n",
      "Epoch: 3  Validation accuracy: 98.6779%  Average Loss: 0.740433\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.62504\n",
      "Epoch: 4  Training accuracy: 98.9146%  Average Loss: 0.695651\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.67197\n",
      "Epoch: 4  Validation accuracy: 98.6579%  Average Loss: 0.646053\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.58233\n",
      "Epoch: 5  Training accuracy: 99.1204%  Average Loss: 0.612770\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.55896\n",
      "Epoch: 5  Validation accuracy: 98.9383%  Average Loss: 0.587162\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.56698\n",
      "Epoch: 6  Training accuracy: 99.2188%  Average Loss: 0.559014\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.52853\n",
      "Epoch: 6  Validation accuracy: 98.9183%  Average Loss: 0.552298\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.53203\n",
      "Epoch: 7  Training accuracy: 99.3389%  Average Loss: 0.519484\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.49083\n",
      "Epoch: 7  Validation accuracy: 99.0785%  Average Loss: 0.518653\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.47619\n",
      "Epoch: 8  Training accuracy: 99.4464%  Average Loss: 0.487935\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.52178\n",
      "Epoch: 8  Validation accuracy: 98.9784%  Average Loss: 0.497139\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.47817\n",
      "Epoch: 9  Training accuracy: 99.4901%  Average Loss: 0.461381\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.47529\n",
      "Epoch: 9  Validation accuracy: 99.0785%  Average Loss: 0.473049\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.45107\n",
      "Epoch: 10  Training accuracy: 99.5575%  Average Loss: 0.440051\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.47826\n",
      "Epoch: 10  Validation accuracy: 99.0385%  Average Loss: 0.462670\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.42714\n",
      "Epoch: 11  Training accuracy: 99.5830%  Average Loss: 0.422532\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.48075\n",
      "Epoch: 11  Validation accuracy: 99.1186%  Average Loss: 0.447283\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.46920\n",
      "Epoch: 12  Training accuracy: 99.6412%  Average Loss: 0.406496\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.42304\n",
      "Epoch: 12  Validation accuracy: 99.0986%  Average Loss: 0.434465\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.37404\n",
      "Epoch: 13  Training accuracy: 99.6722%  Average Loss: 0.393535\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.43699\n",
      "Epoch: 13  Validation accuracy: 99.1587%  Average Loss: 0.424601\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.32353\n",
      "Epoch: 14  Training accuracy: 99.7086%  Average Loss: 0.377129\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.47253\n",
      "Epoch: 14  Validation accuracy: 99.0986%  Average Loss: 0.417895\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.35536\n",
      "Epoch: 15  Training accuracy: 99.7359%  Average Loss: 0.368665\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.40656\n",
      "Epoch: 15  Validation accuracy: 99.1987%  Average Loss: 0.413463\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.34853\n",
      "Epoch: 16  Training accuracy: 99.7760%  Average Loss: 0.358240\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.41084\n",
      "Epoch: 16  Validation accuracy: 99.1787%  Average Loss: 0.403610\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.36405\n",
      "Epoch: 17  Training accuracy: 99.7778%  Average Loss: 0.351286\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.41448\n",
      "Epoch: 17  Validation accuracy: 99.1787%  Average Loss: 0.397804\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.31958\n",
      "Epoch: 18  Training accuracy: 99.7942%  Average Loss: 0.341042\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.35514\n",
      "Epoch: 18  Validation accuracy: 99.1987%  Average Loss: 0.392882\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.32371\n",
      "Epoch: 19  Training accuracy: 99.8070%  Average Loss: 0.333410\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.39397\n",
      "Epoch: 19  Validation accuracy: 99.2388%  Average Loss: 0.392174\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.32974\n",
      "Epoch: 20  Training accuracy: 99.8598%  Average Loss: 0.328341\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.39583\n",
      "Epoch: 20  Validation accuracy: 99.1787%  Average Loss: 0.392022\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.30349\n",
      "Epoch: 21  Training accuracy: 99.8379%  Average Loss: 0.320290\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.38003\n",
      "Epoch: 21  Validation accuracy: 99.2588%  Average Loss: 0.384516\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.28976\n",
      "Epoch: 22  Training accuracy: 99.8580%  Average Loss: 0.316116\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.38080\n",
      "Epoch: 22  Validation accuracy: 99.2388%  Average Loss: 0.380885\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.29850\n",
      "Epoch: 23  Training accuracy: 99.8889%  Average Loss: 0.308189\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.36452\n",
      "Epoch: 23  Validation accuracy: 99.3189%  Average Loss: 0.380207\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.30151\n",
      "Epoch: 24  Training accuracy: 99.8780%  Average Loss: 0.304409\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.38148\n",
      "Epoch: 24  Validation accuracy: 99.2788%  Average Loss: 0.374385\n",
      "\n",
      "Training the model, Iteration: 429/429 Loss: 0.26273\n",
      "Epoch: 25  Training accuracy: 99.8853%  Average Loss: 0.299380\n",
      "Evaluating the model, Iteration: 39/39 Val Loss: 0.33612\n",
      "Epoch: 25  Validation accuracy: 99.2388%  Average Loss: 0.372461\n",
      "\n",
      "Training the model, Iteration: 179/429 Loss: 0.29827"
     ]
    }
   ],
   "source": [
    "epochNum = 100\n",
    "batch_size = 128\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "iterNum_train = mnist.train.num_examples // batch_size\n",
    "iterNum_valid = mnist.validation.num_examples // batch_size\n",
    "iterNum_test = mnist.test.num_examples // batch_size\n",
    "\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "\n",
    "    for epoch in range(epochNum):\n",
    "        taccs = []\n",
    "        tlosses = []\n",
    "        for i in range(1, iterNum_train + 1):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "\n",
    "            _, loss_train = sess.run(\n",
    "                [training_op, loss],\n",
    "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                           y: y_batch,\n",
    "                           masked_labels: True})\n",
    "            \n",
    "            tlosses.append(loss_train)\n",
    "            taccs.append(accuracy.eval(feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                           y: y_batch,\n",
    "                           masked_labels: True}))\n",
    "            print(\"\\rTraining the model, Iteration: {}/{} Loss: {:.5f}\".format(i, iterNum_train,loss_train),end=\"\")\n",
    "        print(\"\\r\")\n",
    "        mean_tacc = np.mean(taccs)\n",
    "        mean_tloss = np.mean(tlosses)\n",
    "        print(\"Epoch: {}  Training accuracy: {:.4f}%  Average Loss: {:.6f}\".format(epoch + 1, mean_tacc * 100, mean_tloss))\n",
    "        \n",
    "        vlosses = []\n",
    "        vaccs = []\n",
    "        for i in range(1, iterNum_valid + 1):\n",
    "            X_batch, y_batch = mnist.validation.next_batch(batch_size)\n",
    "            vloss, vacc = sess.run(\n",
    "                    [loss, accuracy],\n",
    "                    feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                               y: y_batch})\n",
    "            vlosses.append(vloss)\n",
    "            vaccs.append(vacc)\n",
    "            print(\"\\rEvaluating the model, Iteration: {}/{} Val Loss: {:.5f}\".format(i, iterNum_valid, vloss),end=\"\")\n",
    "        print(\"\\r\")\n",
    "        mean_vacc = np.mean(vaccs)\n",
    "        mean_vloss = np.mean(vlosses)\n",
    "        print(\"Epoch: {}  Validation accuracy: {:.4f}%  Average Loss: {:.6f}\".format(epoch + 1, mean_vacc * 100, mean_vloss,\n",
    "            \" (improved)\" if mean_vloss < best_loss else \"\"))\n",
    "\n",
    "        if mean_vloss < best_loss:\n",
    "            best_loss = mean_vloss\n",
    "        print()\n",
    "\n",
    "    saver.save(sess, './model2.ckpt')\n",
    "    \n",
    "    tlosses = []\n",
    "    taccs = []\n",
    "    for i in range(1, iterNum_test + 1):\n",
    "        X_batch, y_batch = mnist.test.next_batch(batch_size)\n",
    "        tloss, tacc = sess.run(\n",
    "                [loss, accuracy],\n",
    "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                           y: y_batch})\n",
    "        tlosses.append(tloss)\n",
    "        taccs.append(tacc)\n",
    "        print(\"\\rEvaluating the model, Iteration: {}/{}\".format(i, iterNum_test),end=\"\")\n",
    "\n",
    "    mean_tloss = np.mean(tlosses)\n",
    "    mean_tacc = np.mean(taccs)\n",
    "    print(\"\\nTest Accuracy: {:.4f}%  Loss: {:.6f}\".format(mean_tacc * 100, mean_tloss))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampleNum = 6\n",
    "\n",
    "sample_images = mnist.test.images[:sampleNum].reshape([-1, 28, 28, 1])\n",
    "\n",
    "reconstruction_labels = []\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./model2.ckpt')\n",
    "    v_j_value, y_pred_value, decoder_output_value, reconstruction_value  = sess.run(\n",
    "            [v_j, y_pred, decoder_output, reconstruction_mask],\n",
    "            feed_dict={X: sample_images,\n",
    "                       y: np.array([], dtype=np.int64)})\n",
    "    \n",
    "    for i in range(sampleNum):\n",
    "        reconstruction_labels.append(sess.run(tf.argmax(reconstruction_value[i], axis=0)))\n",
    "    \n",
    "sample_images = sample_images.reshape(-1, 28, 28)\n",
    "reconstructions = decoder_output_value.reshape([-1, 28, 28])\n",
    "\n",
    "print(\"Sample MNIST test reconstructions of a CapsNet with 3 routing iterations\")\n",
    "print(\"(l,p,r)\")\n",
    "\n",
    "f_in = plt.figure(figsize=(sampleNum * 2, 2))\n",
    "for index in range(sampleNum): \n",
    "    plt.subplot(1, sampleNum, index + 1)\n",
    "    plt.imshow(sample_images[index], cmap=\"gray\")\n",
    "    plt.title( \"(\"+str(mnist.test.labels[index])+','+ str(y_pred_value[index])+','+str(reconstruction_labels[index])+\")\")\n",
    "    plt.axis(\"tight\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "f_out = plt.figure(figsize=(sampleNum * 2, 2))\n",
    "for index in range(sampleNum):\n",
    "    plt.subplot(1, sampleNum, index + 1)\n",
    "    plt.imshow(reconstructions[index], cmap=\"gray\")\n",
    "    plt.axis(\"tight\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The label $(l,p,r)$ above the images represents the label, the prediction and the reconstruction target respectively.\n",
    "+ The images on the first row are the input images, and that on the second row are the reconstructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What the Individual Dimensions of a Capsule Represent\n",
    "+ We can see what the individual dimensions represent by feeding a perturbed version of the activity vector to the decoder network and see how the perturbation affects the reconstruction.\n",
    "+ The dimension of the DigitCaps representation is tweaked by intervals of 0.05 in the range [−0.25, 0.25].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepNum = 11\n",
    "\n",
    "\n",
    "def tweak_digit_dim(output_vectors, min=-0.5, max=0.5, stepNum=stepNum):\n",
    "    steps = np.linspace(min, max, stepNum)\n",
    "    digit_dim = np.arange(16)\n",
    "    tweaks = np.zeros([16, stepNum, 1, 1, 1, 16, 1])\n",
    "    tweaks[digit_dim, :, 0, 0, 0, digit_dim, 0] = steps\n",
    "    output_vectors_expanded = output_vectors[np.newaxis, np.newaxis]\n",
    "    return tweaks + output_vectors_expanded\n",
    "\n",
    "\n",
    "tweaked_vectors = tweak_digit_dim(v_j_value, stepNum=stepNum)\n",
    "tweaked_vectors_reshaped = tweaked_vectors.reshape([-1, 1, 10, 16, 1])\n",
    "\n",
    "\n",
    "tweak_labels = np.tile(mnist.test.labels[:sampleNum], 16 * stepNum)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './model2.ckpt')\n",
    "    decoder_output_value = sess.run(decoder_output,\n",
    "                                    feed_dict={v_j: tweaked_vectors_reshaped,\n",
    "                                               masked_labels: True,\n",
    "                                               y: tweak_labels})\n",
    "\n",
    "tweak_reconstructions = decoder_output_value.reshape([16, stepNum, sampleNum, 28, 28])\n",
    "\n",
    "print(\"16 dimensions tweaked by intervals of 0.05\")\n",
    "\n",
    "for dim in range(16):\n",
    "    print(\"Dimension {}\".format(dim))\n",
    "    plt.figure(figsize=(stepNum / 1.2, sampleNum / 1.5))\n",
    "    for row in range(sampleNum):\n",
    "        for col in range(stepNum):\n",
    "            plt.subplot(sampleNum, stepNum, row * stepNum + col + 1)\n",
    "            plt.imshow(tweak_reconstructions[dim, col, row], cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
